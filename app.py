# Streamlit Amazon Fee Analyzerï¼ˆä¸­æ–‡è¡¨å¤´ç‰ˆï¼šSKU æ±‡æ€» + ASIN + æˆæœ¬/æ¯›åˆ© + å»ºè®®å”®ä»·ï¼‰
# ---------------------------------------------------------------------------
# éƒ¨ç½²è¯´æ˜ï¼ˆGitHub + Streamlit Cloudï¼‰
# 1) ä»“åº“å†…æ”¾ä¸¤ä¸ªæ–‡ä»¶ï¼š
#    - app.py  ï¼ˆæœ¬æ–‡ä»¶ï¼‰
#    - requirements.txt  å†…å®¹ï¼š
#        streamlit
#        pandas
#        openpyxl
# 2) åœ¨ streamlit.io é€‰æ‹©è¯¥ä»“åº“å¹¶æŒ‡å®š app.py éƒ¨ç½²ã€‚
# 
# æœ¬åº”ç”¨æ”¯æŒï¼š
# â€¢ ä¸Šä¼  Amazon Date Range/Settlement æŠ¥è¡¨ï¼ˆCSV/XLSXï¼‰ï¼Œè‡ªåŠ¨è¯†åˆ«è¡¨å¤´ã€åˆ†éš”ç¬¦ã€ç¼–ç ï¼Œè·³è¿‡å‰è¨€è¡Œï¼›
# â€¢ å¯é€‰ä¸Šä¼  æˆæœ¬é…ç½®è¡¨ï¼ˆæ”¯æŒ skuã€unit_costã€inboundã€packagingã€extraã€vat_rateã€å¯é€‰ asinï¼‰ï¼›
# â€¢ å¯é€‰ä¸Šä¼  ç›®å½•/Listing æ˜ å°„è¡¨ï¼ˆsku, asinï¼‰ï¼Œå½“äº¤æ˜“æŠ¥è¡¨æ²¡æœ‰ ASIN æ—¶è¡¥é½ï¼›
# â€¢ ä¾§è¾¹æ è®¾ç½®ï¼šæ˜¯å¦ç”¨å«ç¨ä»·æ˜¾ç¤ºè´¹ç‡ã€æ¶¨ä»·é˜ˆå€¼ã€ç›®æ ‡è´¹ç”¨å æ¯”ã€ç›®æ ‡æ¯›åˆ©ç‡ã€æ˜¯å¦ä¸­æ–‡è¡¨å¤´ï¼›
# â€¢ è¾“å‡ºï¼šæ¯ SKUï¼ˆæˆ– SKU+ASINï¼‰å¹³å‡å”®ä»·ã€è´¹ç”¨ç»“æ„ã€è´¹ç”¨å æ¯”ã€æ˜¯å¦å»ºè®®æ¶¨ä»·ã€å»ºè®®å”®ä»·ï¼ˆè¾¾æˆç›®æ ‡è´¹ç”¨å æ¯”ï¼‰ã€
#         æ¯›åˆ©/æ¯›åˆ©ç‡ï¼ˆä¸å«ç¨å£å¾„ï¼‰åŠä¸ºè¾¾æˆç›®æ ‡æ¯›åˆ©ç‡çš„å»ºè®®å”®ä»·ï¼ˆä¸å«ç¨/å«ç¨ï¼‰ã€‚

import io
import math
from typing import Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

st.set_page_config(page_title="Amazon è´¹ç”¨ä¸åˆ©æ¶¦åˆ†æ", layout="wide")

st.title("ğŸ“Š Amazon è´¹ç”¨ä¸åˆ©æ¶¦åˆ†æ â€” SKU/ASIN å®šä»·å»ºè®®ï¼ˆä¸­æ–‡è¡¨å¤´ç‰ˆï¼‰")
st.caption("ä¸Šä¼  Amazon æŠ¥è¡¨ï¼ˆCSV/XLSXï¼‰+ å¯é€‰æˆæœ¬/ç›®å½•è¡¨ï¼Œè‡ªåŠ¨è®¡ç®—è´¹ç”¨å æ¯”ã€æ¯›åˆ©ä¸å»ºè®®å”®ä»·ã€‚")

# ==========================
# å·¥å…·æ–¹æ³•
# ==========================

def _lower_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip().lower() for c in df.columns]
    return df

# æŠ¥è¡¨åˆ—ååˆ«åæ˜ å°„
COL_ALIASES: Dict[str, List[str]] = {
    "date": ["date/time", "date", "posted date", "posteddate", "transaction posted date"],
    "order_id": ["order id", "amazon order id", "amazonorderid"],
    "sku": ["sku", "merchant_sku", "seller-sku", "seller sku", "seller sku id", "sku number"],
    # æ”¶å…¥
    "principal": ["product sales", "principal", "item-price", "item price"],
    "tax": ["product sales tax", "tax", "item-tax", "item tax"],
    # è´¹ç”¨
    "selling_fees": ["selling fees", "commission", "referral fee", "selling fee"],
    "fba_fees": [
        "fba fees",
        "fbaperunitfulfillmentfee",
        "fulfillment fee",
        "fulfilment fee",
        "fulfillment-fee",
    ],
    "other_txn_fees": ["other transaction fees", "shipping chargeback", "shippingchargeback"],
    "other": ["other"],
    "qty": ["quantity", "qty"],
    "type": ["type"],
    "marketplace": ["marketplace"],
    "asin": ["asin", "asin/isbn", "asin / isbn", "asin (child)", "asin (parent)"]
}

# æˆæœ¬è¡¨åˆ«å
COST_ALIASES: Dict[str, List[str]] = {
    "sku": ["sku", "seller-sku", "merchant_sku"],
    "unit_cost": ["unit_cost", "cogs", "cost", "unit cost"],
    "inbound": ["inbound", "inbound_per_unit", "inbound cost", "inbound_peru", "freight", "shipping"],
    "packaging": ["packaging", "packaging_per_unit", "pack", "pack cost"],
    "extra": ["extra", "extra_per_unit", "overhead", "other_cost"],
    "vat_rate": ["vat_rate", "vat", "vat %", "vat percent", "vatpercentage"],
    "asin": ["asin", "asin/isbn", "asin (child)", "asin (parent)"]
}

# ç›®å½•è¡¨ï¼ˆsku, asinï¼‰åˆ«å
CATALOG_ALIASES: Dict[str, List[str]] = {
    "sku": ["sku", "seller-sku", "merchant_sku"],
    "asin": ["asin", "asin/isbn", "asin (child)", "asin (parent)"]
}


def pick_col(df: pd.DataFrame, keys: List[str]) -> Optional[str]:
    cols = set(df.columns)
    for k in keys:
        if k in cols:
            return k
    return None


def auto_map_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:
    dfl = _lower_cols(df)
    mapping: Dict[str, Optional[str]] = {}
    for std_name, aliases in COL_ALIASES.items():
        mapping[std_name] = pick_col(dfl, [a.lower() for a in aliases])
    return mapping


def auto_map_cost_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:
    dfl = _lower_cols(df)
    mapping: Dict[str, Optional[str]] = {}
    for std_name, aliases in COST_ALIASES.items():
        mapping[std_name] = pick_col(dfl, [a.lower() for a in aliases])
    return mapping


def auto_map_catalog_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:
    dfl = _lower_cols(df)
    mapping: Dict[str, Optional[str]] = {}
    for std_name, aliases in CATALOG_ALIASES.items():
        mapping[std_name] = pick_col(dfl, [a.lower() for a in aliases])
    return mapping


def coerce_number(s):
    """é‡‘é¢å­—ç¬¦ä¸²è½¬æµ®ç‚¹ï¼Œæ”¯æŒ( )è´Ÿå·ã€è´§å¸ç¬¦å·ã€åƒåˆ†ä½ã€‚"""
    if isinstance(s, (int, float)):
        return float(s)
    if s is None:
        return 0.0
    t = str(s).strip()
    if t == "" or t.lower() in {"nan", "none"}:
        return 0.0
    t = t.replace(",", "").replace("Â£", "").replace("Â¥", "").replace("$", "")
    neg = False
    if t.startswith("(") and t.endswith(")"):
        neg = True
        t = t[1:-1]
    try:
        v = float(t)
        return -v if neg else v
    except Exception:
        return 0.0

# ==========================
# æ–‡ä»¶è¯»å–ï¼ˆé²æ£’ï¼‰
# ==========================

def _detect_header_row_and_sep(text: str) -> Tuple[int, str]:
    """è‡ªåŠ¨å®šä½æ•°æ®è¡¨å¤´è¡Œä¸åˆ†éš”ç¬¦ï¼ˆé€—å·/åˆ†å·/Tab/ç«–çº¿ï¼‰ã€‚"""
    lines = text.splitlines()
    seps = [",", ";", "	", "|"]
    target_tokens = ["order", "sku"]
    for i in range(min(50, len(lines))):
        raw = lines[i].lower()
        for sep in seps:
            cells = [c.strip() for c in raw.split(sep)]
            if sum(any(tok in c for c in cells) for tok in target_tokens) >= 2:
                return i, sep
    # å…œåº•ï¼šæŒ‰åˆ—æ•°æœ€å¤šçš„è¡ŒçŒœæµ‹
    max_cols, best_sep, best_i = 0, ",", 0
    for i in range(min(50, len(lines))):
        for sep in seps:
            cols = len(lines[i].split(sep))
            if cols > max_cols:
                max_cols, best_sep, best_i = cols, sep, i
    return best_i, best_sep


def read_amazon_report(uploaded_file) -> pd.DataFrame:
    name = uploaded_file.name.lower()
    data = uploaded_file.read()
    if name.endswith((".xlsx", ".xls")):
        return pd.read_excel(io.BytesIO(data))
    for enc in ("utf-8-sig", "utf-8", "cp1252"):
        try:
            text = data.decode(enc, errors="replace")
            hdr_idx, sep = _detect_header_row_and_sep(text)
            return pd.read_csv(io.StringIO(text), skiprows=hdr_idx, sep=sep, engine="python")
        except Exception:
            continue
    return pd.read_csv(io.BytesIO(data), sep=None, engine="python", on_bad_lines="skip")


def read_any_csv_like(uploaded_file) -> pd.DataFrame:
    name = uploaded_file.name.lower()
    if name.endswith((".xlsx", ".xls")):
        return pd.read_excel(uploaded_file)
    uploaded_file.seek(0)
    data = uploaded_file.read()
    for enc in ("utf-8-sig", "utf-8", "cp1252"):
        try:
            text = data.decode(enc, errors="replace")
            return pd.read_csv(io.StringIO(text), engine="python")
        except Exception:
            continue
    return pd.read_csv(io.BytesIO(data), sep=None, engine="python", on_bad_lines="skip")

# ==========================
# æ ¸å¿ƒæ±‡æ€»
# ==========================

def build_summary(
    df_raw: pd.DataFrame,
    include_tax: bool = True,
    raise_fee_abs_threshold: float = 5.0,
    raise_fee_ratio_threshold: float = 0.50,
    target_fee_ratio: float = 0.40,
    target_margin: float = 0.30,
    cost_df: Optional[pd.DataFrame] = None,
    catalog_df: Optional[pd.DataFrame] = None,
) -> pd.DataFrame:
    df = _lower_cols(df_raw)
    cols = auto_map_columns(df)

    required = ["sku", "principal", "selling_fees", "fba_fees"]
    missing = [r for r in required if not cols.get(r)]
    if missing:
        raise ValueError(f"ç¼ºå°‘å…³é”®åˆ—: {missing}. ç°æœ‰åˆ—ä¸¾ä¾‹: {list(df.columns)[:20]} ...")

    sku_col = cols["sku"]
    principal_col = cols["principal"]
    tax_col = cols.get("tax")
    selling_col = cols["selling_fees"]
    fba_col = cols["fba_fees"]
    other_txn_col = cols.get("other_txn_fees")
    other_col = cols.get("other")
    qty_col = cols.get("qty")
    asin_col = cols.get("asin")

    # æ•°å€¼åŒ–
    for c in [principal_col, tax_col, selling_col, fba_col, other_txn_col, other_col]:
        if c and c in df.columns:
            df[c] = df[c].map(coerce_number)

    df["price_incl_tax"] = df[principal_col] + (df[tax_col] if include_tax and tax_col else 0.0)
    df["price_ex_vat"] = df[principal_col]

    df["commission_fee"] = df[selling_col].fillna(0)
    df["fba_fee"] = df[fba_col].fillna(0)
    df["other_fees"] = 0.0
    if other_txn_col:
        df["other_fees"] += df[other_txn_col].fillna(0)
    if other_col:
        df["other_fees"] += df[other_col].fillna(0)

    df["fees_total"] = df["commission_fee"] + df["fba_fee"] + df["other_fees"]

    if qty_col and qty_col in df.columns:
        df[qty_col] = df[qty_col].apply(lambda x: coerce_number(x) if pd.notna(x) else 1)
    else:
        df[qty_col or "quantity"] = 1
        qty_col = qty_col or "quantity"

    work = df.loc[df["price_incl_tax"].notna()]

    group_cols = [sku_col] + ([asin_col] if asin_col else [])
    grp = work.groupby(group_cols, dropna=False)
    out = (
        grp.agg(
            orders=(sku_col, "count"),
            units=(qty_col, "sum"),
            avg_price_incl=("price_incl_tax", "mean"),
            avg_price_ex=("price_ex_vat", "mean"),
            avg_commission=("commission_fee", "mean"),
            avg_fba=("fba_fee", "mean"),
            avg_other=("other_fees", "mean"),
        )
        .reset_index()
        .rename(columns={**({sku_col: "SKU"}), **({asin_col: "ASIN"} if asin_col else {})})
    )

    out["avg_fees"] = out["avg_commission"] + out["avg_fba"] + out["avg_other"]
    base_price = out["avg_price_incl"] if include_tax else out["avg_price_ex"]
    out["fee_ratio"] = out["avg_fees"] / base_price.replace({0: math.nan})

    out["raise_price"] = (out["avg_fees"] > raise_fee_abs_threshold) & (out["fee_ratio"] > raise_fee_ratio_threshold)

    out["suggest_price_fee_target_incl"] = out.apply(
        lambda r: (r["avg_fees"] / target_fee_ratio) if include_tax else math.nan, axis=1
    )
    out["suggest_price_fee_target_ex"] = out.apply(
        lambda r: (r["avg_fees"] / target_fee_ratio) if not include_tax else math.nan, axis=1
    )

    # é¢„åˆ›å»ºåˆ©æ¶¦ç›¸å…³åˆ—ï¼ˆå³ä½¿æ— æˆæœ¬è¡¨ä¹Ÿä¸æŠ¥é”™ï¼‰
    out["unit_cost_total"], out["gross_profit_ex"], out["margin_ex"] = math.nan, math.nan, math.nan
    out["suggest_price_margin_ex"], out["suggest_price_margin_incl"] = math.nan, math.nan
    out["commission_rate"] = math.nan
    out["fixed_fees_ex"] = out["avg_fba"] + out["avg_other"]

    # ==== ä»æˆæœ¬è¡¨/ç›®å½•è¡¨è¡¥é½ ASINï¼ˆå½“æŠ¥è¡¨æ—  ASINï¼‰ ====
    def _pick(df, names):
        cols = [c for c in df.columns if c.lower().strip() in [n.lower() for n in names]]
        return cols[0] if cols else None

    if ("ASIN" not in out.columns) and (cost_df is not None) and (not cost_df.empty):
        c = _lower_cols(cost_df)
        sku_c = _pick(c, COST_ALIASES["sku"])
        asin_c = _pick(c, COST_ALIASES["asin"]) if "asin" in COST_ALIASES else None
        if sku_c and asin_c and asin_c in c.columns:
            out = (
                out.merge(c[[sku_c, asin_c]].drop_duplicates(), left_on="SKU", right_on=sku_c, how="left")
                   .rename(columns={asin_c: "ASIN"})
                   .drop(columns=[sku_c])
            )

    if ("ASIN" not in out.columns) and (catalog_df is not None) and (not catalog_df.empty):
        t = _lower_cols(catalog_df)
        sku_t = _pick(t, CATALOG_ALIASES["sku"])
        asin_t = _pick(t, CATALOG_ALIASES["asin"])
        if sku_t and asin_t:
            out = (
                out.merge(t[[sku_t, asin_t]].drop_duplicates(), left_on="SKU", right_on=sku_t, how="left")
                   .rename(columns={asin_t: "ASIN"})
                   .drop(columns=[sku_t])
            )

    # ==== åˆ©æ¶¦ï¼ˆéœ€æˆæœ¬è¡¨ï¼‰ ====
    if cost_df is not None and not cost_df.empty:
        cdf = _lower_cols(cost_df)
        cmap = auto_map_cost_columns(cdf)
        c_sku = cmap.get("sku")
        if not c_sku:
            raise ValueError("æˆæœ¬è¡¨ç¼ºå°‘ SKU åˆ—ï¼ˆæ”¯æŒ sku/seller-sku/merchant_skuï¼‰")
        for key in ["unit_cost", "inbound", "packaging", "extra", "vat_rate"]:
            col = cmap.get(key)
            if col and col in cdf.columns:
                cdf[col] = cdf[col].map(coerce_number)
        unit_cost = cdf[cmap.get("unit_cost")] if cmap.get("unit_cost") in cdf.columns else 0.0
        inbound = cdf[cmap.get("inbound")] if cmap.get("inbound") in cdf.columns else 0.0
        packaging = cdf[cmap.get("packaging")] if cmap.get("packaging") in cdf.columns else 0.0
        extra = cdf[cmap.get("extra")] if cmap.get("extra") in cdf.columns else 0.0
        cdf["unit_cost_total"] = unit_cost.fillna(0) + inbound.fillna(0) + packaging.fillna(0) + extra.fillna(0)
        if cmap.get("vat_rate") and cmap.get("vat_rate") in cdf.columns:
            cdf["vat_rate_norm"] = cdf[cmap["vat_rate"]].apply(lambda v: (v/100.0) if v and abs(v) > 1 else (v if pd.notna(v) else math.nan))
        else:
            cdf["vat_rate_norm"] = math.nan

        cdf_keep = cdf[[c_sku, "unit_cost_total", "vat_rate_norm"]].drop_duplicates()
        out = out.merge(cdf_keep, left_on="SKU", right_on=c_sku, how="left").drop(columns=[c_sku])

        rev_ex = out["avg_price_ex"].copy()
        need_backout = rev_ex.isna() | (rev_ex == 0)
        if need_backout.any():
            out.loc[need_backout & out["vat_rate_norm"].notna(), "avg_price_ex"] = (
                out.loc[need_backout & out["vat_rate_norm"].notna(), "avg_price_incl"] / (1 + out.loc[need_backout & out["vat_rate_norm"].notna(), "vat_rate_norm"])
            )
        rev_ex = out["avg_price_ex"]

        with pd.option_context('mode.use_inf_as_na', True):
            out["commission_rate"] = out["avg_commission"] / rev_ex.replace({0: math.nan})
            out["commission_rate"] = out["commission_rate"].clip(lower=0, upper=0.20)
        out["fixed_fees_ex"] = out["avg_fba"] + out["avg_other"]

        out["unit_cost_total"] = out["unit_cost_total"].astype(float)
        out["gross_profit_ex"] = rev_ex - (out["unit_cost_total"] + out["fixed_fees_ex"] + out["commission_rate"] * rev_ex)
        out["margin_ex"] = out["gross_profit_ex"] / rev_ex.replace({0: math.nan})

        denom = 1 - out["commission_rate"] - target_margin
        out.loc[(denom > 0) & (out["unit_cost_total"].notna()), "suggest_price_margin_ex"] = (
            (out["unit_cost_total"] + out["fixed_fees_ex"]) / denom
        )
        out.loc[out["suggest_price_margin_ex"].notna() & out["vat_rate_norm"].notna(), "suggest_price_margin_incl"] = (
            out["suggest_price_margin_ex"] * (1 + out["vat_rate_norm"])
        )

    # ==== è¾“å‡ºåˆ—é¡ºåºï¼ˆå« ASINï¼‰ ====
    nice = out.copy()
    cols_order = ["SKU"]
    if "ASIN" in nice.columns:
        cols_order.append("ASIN")
    cols_order += [
        "orders", "units",
        "avg_price_incl", "avg_price_ex",
        "avg_commission", "avg_fba", "avg_other", "avg_fees", "fee_ratio", "raise_price",
        "suggest_price_fee_target_incl", "suggest_price_fee_target_ex",
        "unit_cost_total", "commission_rate", "fixed_fees_ex", "gross_profit_ex", "margin_ex",
        "suggest_price_margin_ex", "suggest_price_margin_incl",
    ]
    cols_order = [c for c in cols_order if c in nice.columns]
    nice = nice[cols_order].sort_values(["raise_price", "margin_ex", "fee_ratio", "avg_fees"], ascending=[False, True, False, False]).reset_index(drop=True)
    return nice

# ==========================
# ä¾§è¾¹æ  & ä¸Šä¼ 
# ==========================
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    include_tax = st.toggle("è´¹ç”¨å æ¯”æŒ‰å«ç¨ä»·è®¡ç®—", value=True, help="åªå½±å“è´¹ç”¨%å±•ç¤ºï¼›åˆ©æ¶¦è®¡ç®—ä½¿ç”¨ä¸å«ç¨å£å¾„ã€‚")
    fee_abs = st.number_input("å»ºè®®æ¶¨ä»·ï¼šç»å¯¹è´¹ç”¨é˜ˆå€¼(Â£)", value=5.0, min_value=0.0, step=0.5)
    fee_ratio = st.slider("å»ºè®®æ¶¨ä»·ï¼šè´¹ç”¨å æ¯”é˜ˆå€¼", min_value=0.0, max_value=1.0, value=0.50, step=0.05)
    target_ratio = st.slider("å»ºè®®å”®ä»·çš„ç›®æ ‡è´¹ç”¨å æ¯”", min_value=0.10, max_value=0.90, value=0.40, step=0.05)
    target_margin = st.slider("ç›®æ ‡æ¯›åˆ©ç‡(ä¸å«ç¨)", min_value=0.10, max_value=0.80, value=0.30, step=0.05)
    use_cn_headers = st.toggle("é¡µé¢/å¯¼å‡ºä½¿ç”¨ä¸­æ–‡è¡¨å¤´", value=True)
    include_detail = st.checkbox("Excel å¦å­˜åŸå§‹Sheet(ä½“ç§¯è¾ƒå¤§)", value=False)

uploaded = st.file_uploader("ä¸Šä¼  Amazon æŠ¥è¡¨ CSV / XLSX", type=["csv", "xlsx"])
cost_file = st.file_uploader("(å¯é€‰) æˆæœ¬é…ç½®è¡¨ï¼šsku, unit_cost, inbound, packaging, extra, vat_rate, (å¯é€‰ asin)", type=["csv", "xlsx"], key="cost")
catalog_file = st.file_uploader("(å¯é€‰) ç›®å½•/Listing æ˜ å°„ï¼šsku, asin", type=["csv", "xlsx"], key="catalog")

if not uploaded:
    st.info("ğŸ‘† å…ˆä¸Šä¼ äº¤æ˜“æŠ¥è¡¨ã€‚è‹¥CSVå¸¦å‰è¨€è¯´æ˜æˆ–ç”¨åˆ†å·/Tabåˆ†éš”ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«ã€‚")
    st.stop()

# è¯»å–æ–‡ä»¶
try:
    df_raw = read_amazon_report(uploaded)
except Exception as e:
    st.error(f"äº¤æ˜“æŠ¥è¡¨è¯»å–å¤±è´¥: {e}")
    st.stop()

cost_df = None
if cost_file is not None:
    try:
        cost_df = read_any_csv_like(cost_file)
        st.success(f"å·²è½½å…¥æˆæœ¬è¡¨ï¼š{cost_file.name} â€” {len(cost_df):,} è¡Œ")
    except Exception as e:
        st.warning(f"æˆæœ¬è¡¨è¯»å–å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰ï¼š{e}")

catalog_df = None
if catalog_file is not None:
    try:
        catalog_df = read_any_csv_like(catalog_file)
        st.success(f"å·²è½½å…¥ç›®å½•/Listingï¼š{catalog_file.name} â€” {len(catalog_df):,} è¡Œ")
    except Exception as e:
        st.warning(f"ç›®å½•è¡¨è¯»å–å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰ï¼š{e}")

st.success(f"å·²è½½å…¥äº¤æ˜“æŠ¥è¡¨ï¼š{uploaded.name} â€” {len(df_raw):,} è¡Œ, {len(df_raw.columns)} åˆ—")

# æ±‡æ€»
try:
    summary = build_summary(
        df_raw,
        include_tax=include_tax,
        raise_fee_abs_threshold=fee_abs,
        raise_fee_ratio_threshold=fee_ratio,
        target_fee_ratio=target_ratio,
        target_margin=target_margin,
        cost_df=cost_df,
        catalog_df=catalog_df,
    )
except Exception as e:
    st.exception(e)
    st.stop()

# ==========================
# å±•ç¤ºï¼ˆä¸­æ–‡è¡¨å¤´ï¼‰
# ==========================
CN_MAP = {
    "SKU": "SKU",
    "ASIN": "ASIN",
    "orders": "è®¢å•æ•°",
    "units": "é”€é‡ï¼ˆä»¶ï¼‰",
    "avg_price_incl": "å¹³å‡å«ç¨å”®ä»·",
    "avg_price_ex": "å¹³å‡ä¸å«ç¨å”®ä»·",
    "avg_commission": "å¹³å‡ä½£é‡‘",
    "avg_fba": "å¹³å‡FBAè´¹ç”¨",
    "avg_other": "å…¶ä»–è´¹ç”¨",
    "avg_fees": "æ€»è´¹ç”¨",
    "fee_ratio": "è´¹ç”¨å æ¯”",
    "raise_price": "æ˜¯å¦å»ºè®®æ¶¨ä»·",
    "suggest_price_fee_target_incl": "ç›®æ ‡è´¹ç”¨å æ¯”å»ºè®®å”®ä»·ï¼ˆå«ç¨ï¼‰",
    "suggest_price_fee_target_ex": "ç›®æ ‡è´¹ç”¨å æ¯”å»ºè®®å”®ä»·ï¼ˆä¸å«ç¨ï¼‰",
    "unit_cost_total": "å•ä»¶æˆæœ¬",
    "commission_rate": "ä½£é‡‘ç‡",
    "fixed_fees_ex": "å›ºå®šè´¹ç”¨ï¼ˆä¸å«ç¨ï¼‰",
    "gross_profit_ex": "æ¯›åˆ©ï¼ˆä¸å«ç¨ï¼‰",
    "margin_ex": "æ¯›åˆ©ç‡ï¼ˆä¸å«ç¨ï¼‰",
    "suggest_price_margin_ex": "è¾¾æ ‡æ¯›åˆ©å»ºè®®å”®ä»·ï¼ˆä¸å«ç¨ï¼‰",
    "suggest_price_margin_incl": "è¾¾æ ‡æ¯›åˆ©å»ºè®®å”®ä»·ï¼ˆå«ç¨ï¼‰",
}

st.subheader("ğŸ” SKU/ASIN æ±‡æ€»ï¼ˆç‚¹å‡»åˆ—å¤´å¯æ’åºï¼‰")
fmt = summary.copy()
for c in [
    "avg_price_incl", "avg_price_ex", "avg_commission", "avg_fba", "avg_other", "avg_fees",
    "fixed_fees_ex", "gross_profit_ex", "suggest_price_fee_target_incl", "suggest_price_fee_target_ex",
    "suggest_price_margin_ex", "suggest_price_margin_incl", "unit_cost_total",
]:
    if c in fmt.columns:
        fmt[c] = fmt[c].map(lambda x: "" if pd.isna(x) else f"Â£{x:,.2f}")
if "fee_ratio" in fmt.columns:
    fmt["fee_ratio"] = fmt["fee_ratio"].map(lambda x: "" if pd.isna(x) else f"{x*100:.1f}%")
if "margin_ex" in fmt.columns:
    fmt["margin_ex"] = fmt["margin_ex"].map(lambda x: "" if pd.isna(x) else f"{x*100:.1f}%")
if "commission_rate" in fmt.columns:
    fmt["commission_rate"] = fmt["commission_rate"].map(lambda x: "" if pd.isna(x) else f"{x*100:.1f}%")
fmt["raise_price"] = fmt["raise_price"].map(lambda b: "âœ… å»ºè®®æ¶¨ä»·" if b else "ğŸ‘ å¯ç»´æŒ")

if use_cn_headers:
    fmt = fmt.rename(columns={k: v for k, v in CN_MAP.items() if k in fmt.columns})

st.dataframe(fmt, use_container_width=True, hide_index=True)

# é«˜ä¼˜å…ˆçº§
with st.expander("ğŸ”¥ é«˜è´¹ç”¨å æ¯”æˆ–ä½æ¯›åˆ©ï¼ˆå»ºè®®ä¼˜å…ˆå¤„ç†ï¼‰"):
    hot = summary[(summary.get("raise_price", False)) | (summary.get("margin_ex").notna() & (summary.get("margin_ex") < target_margin))].copy()
    if hot.empty:
        st.write("æš‚æ— å‘½ä¸­é˜ˆå€¼çš„SKU/ASINã€‚")
    else:
        hfmt = hot.copy()
        for c in ["avg_price_incl", "avg_fees", "unit_cost_total", "gross_profit_ex", "suggest_price_margin_incl", "suggest_price_margin_ex"]:
            if c in hfmt.columns:
                hfmt[c] = hfmt[c].map(lambda x: f"Â£{x:,.2f}" if pd.notna(x) else "")
        for c in ["fee_ratio", "margin_ex"]:
            if c in hfmt.columns:
                hfmt[c] = hfmt[c].map(lambda x: f"{x*100:.1f}%" if pd.notna(x) else "")
        if use_cn_headers:
            hfmt = hfmt.rename(columns={k: v for k, v in CN_MAP.items() if k in hfmt.columns})
        st.dataframe(hfmt, use_container_width=True, hide_index=True)

# ==========================
# å¯¼å‡º Excelï¼ˆä¸­æ–‡è¡¨å¤´ï¼‰
# ==========================
st.subheader("ğŸ“¥ å¯¼å‡º Excel")
try:
    export_df = summary.copy()
    if use_cn_headers:
        export_df = export_df.rename(columns={k: v for k, v in CN_MAP.items() if k in export_df.columns})

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        export_df.to_excel(writer, index=False, sheet_name="SKU_æ±‡æ€»")
        ws = writer.book["SKU_æ±‡æ€»"]
        for col in ws.columns:
            max_len = 8
            col_letter = col[0].column_letter
            for cell in col:
                try:
                    val = str(cell.value)
                except Exception:
                    val = ""
                max_len = max(max_len, len(val))
            ws.column_dimensions[col_letter].width = min(max_len + 2, 60)
        if include_detail:
            _lower_cols(df_raw).to_excel(writer, index=False, sheet_name="Detail")
        if cost_df is not None:
            _lower_cols(cost_df).to_excel(writer, index=False, sheet_name="Cost_Config")
        if catalog_df is not None:
            _lower_cols(catalog_df).to_excel(writer, index=False, sheet_name="Catalog_Mapping")

    st.download_button(
        label="â¬‡ï¸ ä¸‹è½½ï¼šAmazon_Fee_Analysis_2025Q4.xlsx",
        data=output.getvalue(),
        file_name="Amazon_Fee_Analysis_2025Q4.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
except Exception as e:
    st.error(f"å¯¼å‡ºå¤±è´¥: {e}")

st.caption("æç¤ºï¼šè‹¥äº¤æ˜“æŠ¥è¡¨æ—  ASINï¼Œå¯ä¸Šä¼  æˆæœ¬è¡¨ï¼ˆå« asin åˆ—ï¼‰æˆ– ç›®å½•è¡¨ï¼ˆsku, asinï¼‰è¡¥é½ã€‚åˆ©æ¶¦ä»¥ä¸å«ç¨å£å¾„è®¡ç®—ï¼›è´¹ç”¨å æ¯”å¯åˆ‡æ¢å«/ä¸å«ç¨æ˜¾ç¤ºã€‚")
